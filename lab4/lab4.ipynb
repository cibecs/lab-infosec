{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1577025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y marginal frequencies: Counter({'1101000': 1296, '1000000': 1287, '1001000': 1282, '1001001': 1272, '0001000': 1244, '1011000': 1232, '1001100': 1228, '1001010': 1159})\n",
      "Z marginal frequencies: Counter({'1001001': 1281, '1000000': 1278, '1001000': 1261, '0001000': 1259, '1101000': 1243, '1001010': 1243, '1001100': 1220, '1011000': 1215})\n",
      "Joint frequencies (Y, Z): Counter({('1001001', '1101000'): 184, ('1001001', '1001001'): 184, ('1101000', '1101000'): 184, ('0001000', '0001000'): 182, ('1000000', '1001010'): 178, ('1101000', '1001100'): 178, ('1001000', '1001000'): 175, ('1000000', '1000000'): 171, ('0001000', '1001000'): 170, ('1001000', '1001001'): 169, ('1001100', '1000000'): 169, ('1001000', '1001100'): 168, ('1001000', '1001010'): 166, ('1011000', '1001001'): 166, ('0001000', '1000000'): 166, ('1000000', '1001001'): 165, ('1000000', '1001000'): 165, ('1001001', '1000000'): 165, ('1001000', '1011000'): 162, ('1011000', '0001000'): 161, ('1101000', '1001010'): 160, ('1000000', '1101000'): 160, ('1001001', '1001100'): 159, ('1101000', '1011000'): 159, ('1001100', '0001000'): 159, ('1001010', '0001000'): 159, ('1001010', '1000000'): 159, ('1001100', '1001010'): 159, ('1000000', '0001000'): 159, ('1101000', '1001001'): 158, ('1001001', '1001000'): 157, ('1001000', '0001000'): 157, ('0001000', '1001001'): 157, ('1001100', '1011000'): 157, ('1011000', '1101000'): 157, ('1101000', '0001000'): 157, ('1001001', '1001010'): 155, ('0001000', '1011000'): 154, ('1001100', '1001000'): 153, ('1011000', '1011000'): 152, ('1101000', '1000000'): 151, ('1011000', '1001100'): 151, ('1001100', '1101000'): 151, ('1011000', '1000000'): 150, ('1000000', '1011000'): 149, ('1101000', '1001000'): 149, ('1011000', '1001010'): 148, ('1001000', '1000000'): 147, ('1011000', '1001000'): 147, ('1001010', '1001000'): 145, ('0001000', '1001010'): 144, ('1001010', '1001100'): 143, ('1001001', '1011000'): 143, ('1001010', '1001001'): 142, ('0001000', '1001100'): 141, ('1001100', '1001100'): 140, ('1001100', '1001001'): 140, ('1000000', '1001100'): 140, ('1001010', '1101000'): 139, ('1001010', '1011000'): 139, ('1001000', '1101000'): 138, ('1001010', '1001010'): 133, ('0001000', '1101000'): 130, ('1001001', '0001000'): 125})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "n_bits = 7\n",
    "error_patterns = ['0' * n_bits] + [\n",
    "    ''.join('1' if i == j else '0' for j in range(n_bits))\n",
    "    for i in range(n_bits)\n",
    "]\n",
    "\n",
    "def apply_error(x, e):\n",
    "    return ''.join(str(int(a) ^ int(b)) for a, b in zip(x, e))\n",
    "\n",
    "def wiretap_channel(x):\n",
    "    e_y = random.choice(error_patterns)\n",
    "    e_z = random.choice(error_patterns)\n",
    "    y = apply_error(x, e_y)\n",
    "    z = apply_error(x, e_z)\n",
    "    return y, z\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "def verify_channel(x, num_samples=10_000):\n",
    "    freq_y = Counter()\n",
    "    freq_z = Counter()\n",
    "    freq_yz = Counter()\n",
    "    for _ in range(num_samples):\n",
    "        y, z = wiretap_channel(x)\n",
    "        freq_y[y] += 1\n",
    "        freq_z[z] += 1\n",
    "        freq_yz[(y, z)] += 1\n",
    "    return freq_y, freq_z, freq_yz\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = '1001000'\n",
    "    fy, fz, fyz = verify_channel(x)\n",
    "    print('Y marginal frequencies:', fy)\n",
    "    print('Z marginal frequencies:', fz)\n",
    "    print('Joint frequencies (Y, Z):', fyz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ed498",
   "metadata": {},
   "source": [
    "I defined the eight allowed error patterns (no error or one flipped bit), wrote a function to XOR an input with a pattern, then built wiretap_channel to sample independent errors for Y and Z. Finally, verify_channel runs many trials for a fixed input to gather marginal and joint frequency counts, demonstrating uniformity and conditional independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: E recovers x exactly in all trials: 10000/10000\n",
      "Reverse: E recovers y exactly in 3428/10000 trials\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = [\n",
    "    [1, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 1, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 1, 0, 1],\n",
    "]\n",
    "\n",
    "col_to_syndrome = {\n",
    "    i: ''.join(str(H[row][i]) for row in range(3))\n",
    "    for i in range(n_bits)\n",
    "}\n",
    "syndrome_to_error = {\n",
    "    ''.join('0' for _ in range(3)): '0' * n_bits,\n",
    "    **{\n",
    "        syn: ''.join('1' if idx == i else '0' for i in range(n_bits))\n",
    "        for idx, syn in col_to_syndrome.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "def syndrome(x):\n",
    "    return ''.join(\n",
    "        str(sum(int(x[j]) * H[i][j] for j in range(n_bits)) % 2)\n",
    "        for i in range(3)\n",
    "    )\n",
    "\n",
    "def error_from_syndrome(s):\n",
    "    return syndrome_to_error.get(s, '0' * n_bits)\n",
    "\n",
    "def correct_with_syndrome(received, sent_syndrome):\n",
    "    recv_syn = syndrome(received)\n",
    "    err_syn = ''.join(str(int(a) ^ int(b)) for a, b in zip(recv_syn, sent_syndrome))\n",
    "    return apply_error(received, error_from_syndrome(err_syn))\n",
    "\n",
    "def forward_reconciliation(x, trials=10000):\n",
    "    fwd_ok = 0\n",
    "    for _ in range(trials):\n",
    "        y, z = wiretap_channel(x)\n",
    "        sent_syn = syndrome(x)\n",
    "        if correct_with_syndrome(z, sent_syn) == x:\n",
    "            fwd_ok += 1\n",
    "    return fwd_ok\n",
    "\n",
    "def reverse_reconciliation(x, trials=10000):\n",
    "    rev_ok = 0\n",
    "    for _ in range(trials):\n",
    "        y, z = wiretap_channel(x)\n",
    "        sent_syn = syndrome(y)\n",
    "        if correct_with_syndrome(z, sent_syn) == y:\n",
    "            rev_ok += 1\n",
    "    return rev_ok\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = '1001000'\n",
    "    fwd_success = forward_reconciliation(x)\n",
    "    rev_success = reverse_reconciliation(x)\n",
    "    print(f'Forward: E recovers x exactly in all trials: {fwd_success}/10000')\n",
    "    print(f'Reverse: E recovers y exactly in {rev_success}/10000 trials')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c3ea3",
   "metadata": {},
   "source": [
    "I extended the previous channel code with Hamming‐(7,4) syndrome functions and single‐error correction. The two reconciliation routines simulate many runs: in forward mode Eve always corrects her copy z back to x, while in reverse mode her correction of z toward y succeeds only on a fraction of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d964a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic y' counts: Counter({'1010': 679, '1011': 658, '0011': 653, '1100': 649, '1111': 640, '1110': 630, '0101': 629, '1101': 622, '0111': 617, '0100': 615, '1000': 614, '0010': 610, '0001': 603, '0000': 602, '1001': 592, '0110': 587})\n",
      "Max deviation P(y'|c) vs P(y'): 0.01723269537480064\n",
      "l=1  max dev wrt c: 0.0071, wrt z: 0.3953\n",
      "l=2  max dev wrt c: 0.0053, wrt z: 0.1653\n",
      "l=3  max dev wrt c: 0.0038, wrt z: 0.2874\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "A = [\n",
    "    [1,0,0,0,0,0,1],\n",
    "    [0,1,0,0,1,1,0],\n",
    "    [0,0,1,0,1,0,0],\n",
    "    [0,0,0,1,1,0,0],\n",
    "]\n",
    "\n",
    "def det_priv_ampl(y):\n",
    "    return ''.join(str(sum(int(y[j]) * A[i][j] for j in range(7)) % 2) for i in range(4))\n",
    "\n",
    "def random_linear_hash(l):\n",
    "    return [[random.randint(0,1) for _ in range(4)] for _ in range(l)]\n",
    "\n",
    "def apply_hash(y_p, U):\n",
    "    return ''.join(str(sum(int(y_p[j]) * U[i][j] for j in range(4)) % 2) for i in range(len(U)))\n",
    "\n",
    "def test_det_ampl(trials=10000):\n",
    "    f_global = Counter()\n",
    "    f_cond = {}\n",
    "    for _ in range(trials):\n",
    "        x = ''.join(random.choice('01') for _ in range(7))\n",
    "        y, _ = wiretap_channel(x)\n",
    "        c = syndrome(x)\n",
    "        y_p = det_priv_ampl(y)\n",
    "        f_global[y_p] += 1\n",
    "        f_cond.setdefault(c, Counter())[y_p] += 1\n",
    "    total = sum(f_global.values())\n",
    "    devs = []\n",
    "    for counter in f_cond.values():\n",
    "        tot = sum(counter.values())\n",
    "        for y_p, cnt in counter.items():\n",
    "            devs.append(abs(cnt/tot - f_global[y_p]/total))\n",
    "    return f_global, max(devs)\n",
    "\n",
    "def test_prob_ampl(trials=200000):\n",
    "    results = {}\n",
    "    for l in (1,2,3):\n",
    "        U = random_linear_hash(l)\n",
    "        f_global = Counter()\n",
    "        f_c = {}\n",
    "        f_z = {}\n",
    "        for _ in range(trials):\n",
    "            x = ''.join(random.choice('01') for _ in range(7))\n",
    "            _, z = wiretap_channel(x)\n",
    "            c = syndrome(x)\n",
    "            y_p = det_priv_ampl(x)\n",
    "            k = apply_hash(y_p, U)\n",
    "            f_global[k] += 1\n",
    "            f_c.setdefault(c, Counter())[k] += 1\n",
    "            f_z.setdefault(z, Counter())[k] += 1\n",
    "        total = sum(f_global.values())\n",
    "        dev_c = max(\n",
    "            abs(cnt/sum(counter.values()) - f_global[k]/total)\n",
    "            for counter in f_c.values() for k, cnt in counter.items()\n",
    "        )\n",
    "        dev_z = max(\n",
    "            abs(cnt/sum(counter.values()) - f_global[k]/total)\n",
    "            for counter in f_z.values() for k, cnt in counter.items()\n",
    "        )\n",
    "        results[l] = (dev_c, dev_z)\n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f_global, det_dev = test_det_ampl()\n",
    "    print('Deterministic y\\' counts:', f_global)\n",
    "    print('Max deviation P(y\\'|c) vs P(y\\'):', det_dev)\n",
    "    prob_results = test_prob_ampl()\n",
    "    for l, (dev_c, dev_z) in prob_results.items():\n",
    "        print(f'l={l}  max dev wrt c: {dev_c:.4f}, wrt z: {dev_z:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e2a9d",
   "metadata": {},
   "source": [
    "I added the 4×7 matrix A and wrote det_priv_ampl for y′=Ay mod 2. In test_det_ampl I sample random x, y, compute syndrome c and y′, then measure the max deviation between P(y′|c) and P(y′) to confirm uniformity and independence. In test_prob_ampl I build random ℓ×4 hashes for ℓ=1,2,3, apply them to y′=Ax for the forward‐reconciled string, and compute the max deviations of P(k|c) and P(k|z) from P(k) to identify which ℓ yields full secrecy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b792a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate bit error rate ≈ 0.100\n",
      "Eavesdropper bit error rate ≈ 0.050\n",
      "Protocol reliability: 0.848\n",
      "Eavesdropper success: 0.957\n"
     ]
    }
   ],
   "source": [
    "def bsc_channel(x, error_rate):\n",
    "    return ''.join(str(int(a) ^ (random.random() < error_rate)) for a in x)\n",
    "\n",
    "def wiretap_bsc(x, eps, delta):\n",
    "    return bsc_channel(x, eps), bsc_channel(x, delta)\n",
    "\n",
    "def bit_error_stats(length=100000, eps=0.1, delta=0.05):\n",
    "    orig = ''.join(random.choice('01') for _ in range(length))\n",
    "    y, z = bsc_channel(orig, eps), bsc_channel(orig, delta)\n",
    "    err_y = sum(o != r for o, r in zip(orig, y))\n",
    "    err_z = sum(o != r for o, r in zip(orig, z))\n",
    "    return err_y/length, err_z/length\n",
    "\n",
    "def simulate_protocol(rounds=10000, eps=0.1, delta=0.05):\n",
    "    reliable = 0\n",
    "    eavesdropped = 0\n",
    "    for _ in range(rounds):\n",
    "        x = ''.join(random.choice('01') for _ in range(7))\n",
    "        y, z = wiretap_bsc(x, eps, delta)\n",
    "        c = syndrome(x)\n",
    "        x_hat = correct_with_syndrome(y, c)\n",
    "        x_e = correct_with_syndrome(z, c)\n",
    "        if x_hat == x:\n",
    "            reliable += 1\n",
    "        if x_e == x:\n",
    "            eavesdropped += 1\n",
    "    return reliable/rounds, eavesdropped/rounds\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ey, ez = bit_error_stats()\n",
    "    print(f'Legitimate bit error rate ≈ {ey:.3f}')\n",
    "    print(f'Eavesdropper bit error rate ≈ {ez:.3f}')\n",
    "    rel, eav = simulate_protocol()\n",
    "    print(f'Protocol reliability: {rel:.3f}')\n",
    "    print(f'Eavesdropper success: {eav:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08f217",
   "metadata": {},
   "source": [
    "perfect reliability or secrecy are no longer provided, as there may be more than one error in\n",
    "a single word over the legitimate channel, and the error pattern distribution in the eavesdropper channel\n",
    "is no longer uniform.I added wiretap_bsc using independent binary‐symmetric flips at rates ε and δ, verified the empirical bit‐error rates over a long random string, then ran many protocol rounds feeding BSC outputs into the forward‐reconciliation decoder to show reduced reliability (B recovers x only probabilistically) and that E now sometimes also recovers x exactly, so neither perfect reliability nor secrecy hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38811dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "eps_list = [0.05, 0.1, 0.15]\n",
    "delta = 0.05  # fixed for plotting\n",
    "l_list = [1, 2, 3]\n",
    "trials = 200_000  # Monte Carlo samples\n",
    "\n",
    "# Reuse previously defined functions:\n",
    "#   wiretap_bsc(x, eps, delta)\n",
    "#   syndrome(y)\n",
    "#   correct_with_syndrome(received, sent_syndrome)\n",
    "#   det_priv_ampl(y)\n",
    "#   random_linear_hash(l)\n",
    "#   apply_hash(y_p, U)\n",
    "\n",
    "\n",
    "def simulate_round(eps, delta, U):\n",
    "    x = ''.join(random.choice('01') for _ in range(7))\n",
    "    y, z = wiretap_bsc(x, eps, delta)\n",
    "    # Reverse reconciliation: send syn(y) so A and E correct x->y\n",
    "    c = syndrome(y)\n",
    "    x_A = correct_with_syndrome(x, c)\n",
    "    y_A = det_priv_ampl(x_A)\n",
    "    y_B = det_priv_ampl(y)\n",
    "    k_A = apply_hash(y_A, U)\n",
    "    k_B = apply_hash(y_B, U)\n",
    "    return k_A, k_B, z, c\n",
    "\n",
    "\n",
    "def p_star(kA, kB, l):\n",
    "    # Ideal uniform on diagonal of size 2^l\n",
    "    return (1 / (2 ** l)) if kA == kB else 0\n",
    "\n",
    "\n",
    "def compute_metrics(eps, delta, l):\n",
    "    U = random_linear_hash(l)\n",
    "    joint = Counter()\n",
    "    p_zc = Counter()\n",
    "    marg_kA = Counter()\n",
    "    marg_kB = Counter()\n",
    "\n",
    "    # collect counts\n",
    "    for _ in range(trials):\n",
    "        kA, kB, z, c = simulate_round(eps, delta, U)\n",
    "        joint[(kA, kB, z, c)] += 1\n",
    "        p_zc[(z, c)] += 1\n",
    "        marg_kA[kA] += 1\n",
    "        marg_kB[kB] += 1\n",
    "\n",
    "    # normalize marginals\n",
    "    p_kA = {k: v / trials for k, v in marg_kA.items()}\n",
    "    p_kB = {k: v / trials for k, v in marg_kB.items()}\n",
    "    p_zc = {zc: v / trials for zc, v in p_zc.items()}\n",
    "\n",
    "    # mismatch probability\n",
    "    mismatch = sum(v for (kA, kB, *_), v in joint.items() if kA != kB) / trials\n",
    "\n",
    "    # entropies\n",
    "    H_kA = -sum(p * math.log2(p) for p in p_kA.values() if p > 0)\n",
    "    H_kB = -sum(p * math.log2(p) for p in p_kB.values() if p > 0)\n",
    "\n",
    "    # mutual informations I(K; Z,C)\n",
    "    joint_kA_zc = Counter()\n",
    "    joint_kB_zc = Counter()\n",
    "    for (kA, kB, z, c), v in joint.items():\n",
    "        joint_kA_zc[(kA, z, c)] += v\n",
    "        joint_kB_zc[(kB, z, c)] += v\n",
    "\n",
    "    I_kA_zc = sum((v / trials) * math.log2((v / trials) / (p_kA[kA] * p_zc[(z, c)]))\n",
    "                   for (kA, z, c), v in joint_kA_zc.items())\n",
    "    I_kB_zc = sum((v / trials) * math.log2((v / trials) / (p_kB[kB] * p_zc[(z, c)]))\n",
    "                   for (kB, z, c), v in joint_kB_zc.items())\n",
    "\n",
    "    # total variation distance d_V( p(kA,kB,z,c) , p* p(z,c) )\n",
    "    dV = 0.0\n",
    "    for (kA, kB, z, c), v in joint.items():\n",
    "        p_joint = v / trials\n",
    "        p_model = p_star(kA, kB, l) * p_zc[(z, c)]\n",
    "        dV += abs(p_joint - p_model)\n",
    "    dV *= 0.5\n",
    "\n",
    "    return mismatch, H_kA, H_kB, I_kA_zc, I_kB_zc, dV\n",
    "\n",
    "# Run experiments\n",
    "results = {\n",
    "    (eps, l): compute_metrics(eps, delta, l)\n",
    "    for eps, l in itertools.product(eps_list, l_list)\n",
    "}\n",
    "\n",
    "# Plot 2x3 grid of desired metrics\n",
    "metrics = [\n",
    "    ('Mismatch P[kA!=kB]', 0),\n",
    "    ('ℓ - H(kA)', lambda r, l: l - r[1]),\n",
    "    ('ℓ - H(kB)', lambda r, l: l - r[2]),\n",
    "    ('I(kA;z,c)', 3),\n",
    "    ('I(kB;z,c)', 4),\n",
    "    ('d_V', 5),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for ax, (title, idx_or_fn) in zip(axes.flatten(), metrics):\n",
    "    for l in l_list:\n",
    "        xs = eps_list\n",
    "        ys = []\n",
    "        for eps in eps_list:\n",
    "            r = results[(eps, l)]\n",
    "            if callable(idx_or_fn):\n",
    "                ys.append(idx_or_fn(r, l))\n",
    "            else:\n",
    "                ys.append(r[idx_or_fn])\n",
    "        ax.plot(xs, ys, marker='o', label=f'ℓ={l}')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('ε (δ=0.05)')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a700",
   "metadata": {},
   "source": [
    "I added simulate_round to sample one key‐agreement trial under reverse reconciliation, deterministic and probabilistic privacy amplification, then compute_metrics to estimate P[k_A≠k_B], entropies H(k_A), H(k_B), mutual informations I(k_A;z,c) and I(k_B;z,c), and total variation distance d_V by empirical frequencies. Finally I looped over ε, δ, ℓ, stored results, and plotted key metrics versus ε for fixed δ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033396e",
   "metadata": {},
   "source": [
    "Your figures are qualitatively exactly what you’d expect:\n",
    "\n",
    "Mismatch vs ε\n",
    "As ε increases the legitimate error probability goes up, so P[kA≠kB] grows roughly linearly.\n",
    "\n",
    "ℓ−H(kA) vs ε\n",
    "For ℓ=1,2 you see ℓ−H(kA)≈0 for all ε (your keys are uniform). For ℓ=3 there’s a big bump around ε≈0.1 — that’s exactly the regime where you’ve over-extracted more bits than the secret-key capacity allows, so you no longer get a uniformly distributed key.\n",
    "\n",
    "I(kA;z,c) and I(kB;z,c) vs ε\n",
    "Both leakages drop as ε increases (the more noise on the main channel, the less Eve and Bob correlate with A’s data). You also correctly see I(kA;z,c)≥I(kB;z,c), since A’s version of the key is always at least as well protected as B’s in forward reconciliation.\n",
    "\n",
    "dV vs ε\n",
    "The total-variation distance from the ideal (uniform, independent) distribution decreases as you reduce ℓ or increase ε (more noise “helps” secrecy), and it’s smaller for ℓ=1 than for ℓ=2 than ℓ=3.\n",
    "\n",
    "The only oddity is the little empty subplot (you set up a 3×2 grid but only plotted five metrics), and small statistical wiggles remain because of finite sampling. Increasing your trial count will smooth those out, but the overall trends are correct and entirely consistent with theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
